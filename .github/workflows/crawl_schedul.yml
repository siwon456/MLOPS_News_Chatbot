name: Scheduled News Crawler

on:
  schedule:
    - cron: '0 */2 * * *' # 2시간마다 실행
  workflow_dispatch: # 수동 실행 허용

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: true

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10' # Python 3.10 버전

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        # 기존 라이브러리들
        pip install pandas beautifulsoup4 requests chromadb sentence-transformers langchain-community langchain tqdm
        # 추가: langchain.text_splitter를 포함하는 패키지 설치
        pip install langchain-text-splitters

    - name: Ensure data directory exists
      run: mkdir -p data

    - name: Run data pipeline
      run: python pipeline.py
      env:
        NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
        NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}

    - name: Commit and Push new data
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        
        echo "--- DEBUG: Commit and Push Start ---"
        
        # 3. 수정: 이제는 'chroma_db_merged_all' 폴더만 추가
        git add -f chroma_db_merged_all || true 
        # 'merged_all_news.csv' 파일도 추가
        git add data/merged_all_news.csv || true
        
        if git diff-index --quiet HEAD; then
          echo "No changes detected. Skipping commit and push."
        else
          echo "Changes detected. Proceeding with commit and push."
          git commit -m "Automated data update (Every 2 Hours, Merged DB): $(date +'%Y-%m-%d %H:%M:%S')"
          git pull --rebase
          git push
          echo "--- DEBUG: Commit and Push End ---"
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
